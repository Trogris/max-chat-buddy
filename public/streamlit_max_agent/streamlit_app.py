import streamlit as st
import os
from agent.config import Config
from agent.utils import init_session_state, get_model_info
from agent.rag_store import RAGStore
from agent.chat import MaxChatAgent, display_chat_interface, display_search_interface
from agent.ingest import display_ingestion_interface

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Max - Assistente IA",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    # TÃ­tulo principal
    st.title("ğŸ¤– Max - Assistente de IA da Empresa")
    st.markdown("*Seu assistente inteligente para informaÃ§Ãµes internas e suporte*")
    
    # Inicializa estado da sessÃ£o
    init_session_state()
    
    # Verifica configuraÃ§Ã£o
    try:
        Config.validate()
    except ValueError as e:
        st.error(f"âŒ Erro de configuraÃ§Ã£o: {e}")
        st.info("ğŸ’¡ Configure sua OPENAI_API_KEY no arquivo .env ou nas variÃ¡veis de ambiente")
        st.stop()
    
    # Sidebar - ConfiguraÃ§Ãµes
    with st.sidebar:
        st.header("âš™ï¸ ConfiguraÃ§Ãµes")
        
        # SeleÃ§Ã£o do modelo
        st.subheader("ğŸ¤– Modelo OpenAI")
        
        selected_model = st.selectbox(
            "Escolha o modelo:",
            options=Config.AVAILABLE_MODELS,
            index=Config.AVAILABLE_MODELS.index(st.session_state.current_model) 
                if st.session_state.current_model in Config.AVAILABLE_MODELS 
                else 0,
            help="Selecione o modelo OpenAI para usar nas conversas"
        )
        
        # Atualiza modelo se mudou
        if selected_model != st.session_state.current_model:
            st.session_state.current_model = selected_model
            st.rerun()
        
        # InformaÃ§Ãµes do modelo
        model_info = get_model_info(selected_model)
        st.info(f"**{model_info['name']}**\n\n{model_info['description']}\n\nğŸ“„ Contexto: {model_info['context']}")
        
        st.divider()
        
        # ConfiguraÃ§Ãµes de temperatura
        st.subheader("ğŸŒ¡ï¸ ParÃ¢metros")
        
        temperature = st.slider(
            "Temperatura",
            min_value=0.0,
            max_value=2.0,
            value=Config.TEMPERATURE,
            step=0.1,
            help="Controla a criatividade das respostas (0 = mais focada, 2 = mais criativa)"
        )
        
        max_tokens = st.slider(
            "MÃ¡ximo de Tokens",
            min_value=100,
            max_value=8000,
            value=Config.MAX_TOKENS,
            step=100,
            help="Limita o tamanho das respostas"
        )
        
        # Atualiza configuraÃ§Ãµes
        Config.TEMPERATURE = temperature
        Config.MAX_TOKENS = max_tokens
        
        st.divider()
        
        # InformaÃ§Ãµes da sessÃ£o
        st.subheader("ğŸ“Š SessÃ£o Atual")
        st.metric("Mensagens", len(st.session_state.messages))
        
        if st.session_state.get('documents_ingested'):
            st.metric("Documentos", len(st.session_state.documents_ingested))
    
    # Inicializa componentes
    @st.cache_resource
    def initialize_rag_store():
        return RAGStore()
    
    @st.cache_resource
    def initialize_chat_agent(_rag_store):
        return MaxChatAgent(_rag_store)
    
    rag_store = initialize_rag_store()
    chat_agent = initialize_chat_agent(rag_store)
    
    # Abas principais
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ’¬ Chat", 
        "ğŸ” Busca", 
        "ğŸ“ IngestÃ£o", 
        "â„¹ï¸ Sobre"
    ])
    
    with tab1:
        display_chat_interface(chat_agent)
    
    with tab2:
        display_search_interface(rag_store)
    
    with tab3:
        display_ingestion_interface(rag_store)
    
    with tab4:
        st.header("â„¹ï¸ Sobre o Max")
        
        st.markdown("""
        ### ğŸ¤– O que Ã© o Max?
        
        O Max Ã© seu assistente de IA especializado para informaÃ§Ãµes internas da empresa. 
        Ele combina inteligÃªncia artificial avanÃ§ada com acesso aos documentos e polÃ­ticas 
        da organizaÃ§Ã£o para fornecer respostas precisas e contextualizadas.
        
        ### ğŸš€ Principais Funcionalidades
        
        - **ğŸ’¬ Chat Inteligente**: Converse naturalmente e obtenha respostas baseadas nos documentos internos
        - **ğŸ” Busca AvanÃ§ada**: Encontre rapidamente informaÃ§Ãµes especÃ­ficas na base de conhecimento
        - **ğŸ“ IngestÃ£o de Documentos**: Adicione novos documentos (PDF, DOCX, TXT) Ã  base de conhecimento
        - **ğŸ¤– MÃºltiplos Modelos**: Escolha entre diferentes modelos OpenAI conforme sua necessidade
        
        ### ğŸ’¡ Como Usar
        
        1. **Configure seu modelo** preferido na barra lateral
        2. **Adicione documentos** na aba "IngestÃ£o" para criar sua base de conhecimento
        3. **FaÃ§a perguntas** na aba "Chat" ou **busque informaÃ§Ãµes** na aba "Busca"
        4. **Ajuste parÃ¢metros** como temperatura e tokens conforme necessÃ¡rio
        
        ### ğŸ›¡ï¸ SeguranÃ§a e Privacidade
        
        - Todos os documentos sÃ£o processados localmente
        - As conversas nÃ£o sÃ£o armazenadas permanentemente
        - Sua API key OpenAI Ã© usada apenas para gerar respostas
        
        ### ğŸ”§ Tecnologias Utilizadas
        
        - **Streamlit** - Interface web interativa
        - **OpenAI GPT** - Modelos de linguagem avanÃ§ados
        - **ChromaDB** - Banco de dados vetorial para busca semÃ¢ntica
        - **LangChain** - Framework para aplicaÃ§Ãµes de IA
        
        ---
        
        **VersÃ£o:** 1.0.0 | **Desenvolvido para:** Testes e demonstraÃ§Ã£o
        """)
        
        # EstatÃ­sticas do sistema
        st.subheader("ğŸ“ˆ EstatÃ­sticas do Sistema")
        
        stats = rag_store.get_collection_stats()
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(
                "Documentos na Base",
                stats['total_documents'],
                help="Total de documentos processados e disponÃ­veis para consulta"
            )
        
        with col2:
            st.metric(
                "Modelo de Embedding",
                stats['embedding_model'],
                help="Modelo usado para criar embeddings dos documentos"
            )
        
        with col3:
            st.metric(
                "Modelo de Chat Atual",
                st.session_state.current_model,
                help="Modelo OpenAI atualmente selecionado para conversas"
            )

if __name__ == "__main__":
    main()